---
output:
  md_document:
    variant: markdown_github
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

# Korean Language Demo by Heewon

* The New Year's Day Speech is an important document to understand their plans and changes in goals. By comparing these documents with the previous year, you can see the route changes.
* I will show example of `Hangul(Korean)` processing using North Korea new year speech with [KoNLP](https://CRAN.R-project.org/package=KoNLP).
* `KoNLP`
    + POS Tagger and Morphological Analyzer for Korean text based research. It provides tools for corpus linguistics research such as Keystroke converter, Hangul automata, Concordance, and Mutual Information. It also provides a convenient interface for users to apply, edit and add morphological dictionary selectively.

## install necessary packages 

```{r, eval=FALSE}
install.packages(pkgs = c("Ruchardet", "KoNLP", "tm", "wordcloud", "stringi"))
```


## pre-processing 

- remove unnecessary part(like blank lines)
- unicode normalization

```{r}
library(Ruchardet)
library(stringi)

#euc-kr
nkor_2017_enc <- detectFileEncoding("NK_speech.txt")

nkor_2017 <- readLines("NK_speech.txt", encoding=nkor_2017_enc)

head(nkor_2017, n=3)
```

```{r}
#removing blank lines
nkor_2017_filtered <- Filter(function(x){
  stri_trim(x) != ""}, 
  nkor_2017)

#unicode normalization 
#stri_trans_nfkc("ㄱㅏㄷㅏ") == "가다"

#NFKC normalization 
nkor_2017_filtered_norm <- stri_trans_nfkc(nkor_2017_filtered)
```


## Thematic words(Nouns) extraction using KoNLP


```{r,message=FALSE}
library(KoNLP)

#use one of Korean morphological dictionary 
useNIADic('woorimalsam')

# no need to split sentences =, KoNLP do internally(using  BreakIterator)
#nkor_2017_filtered_norm <- stri_split_boundaries(nkor_2017_filtered_norm, type="sentence")

#extract Nouns 
nkor_2017_nouns <- extractNoun(nkor_2017_filtered_norm)
```


## Make wordcloud 

```{r}
library(wordcloud)

nkor_2017_freq <- table(Filter(function(word){nchar(word) > 1}, unlist(nkor_2017_nouns)))

pal <- brewer.pal(12,"Paired")[-1]

wordcloud(names(nkor_2017_freq), freq = nkor_2017_freq, min.freq=5,
          random.order=F, rot.per=.1,colors=pal)

```


## similarities between words

- make `dtm` object 
- calculate distances between words.
- do hierarchical clustering


```{r,fig.height=7, fig.width=10}
library(tm)

#analyze with only Hangul 
nkor_2017_nouns_han <- sapply(nkor_2017_nouns, function(sent){
  sent[is.hangul(sent) & nchar(sent) > 1]
})


nkor_2017_corp <- Corpus(VectorSource(nkor_2017_nouns_han))

dtm_k_2017 <- TermDocumentMatrix(nkor_2017_corp)

dtm_k_2017_rmsp <- removeSparseTerms(dtm_k_2017, 0.95)


#make distance matrix and plot Hierarchical Clustering
m <-as.matrix(dtm_k_2017_rmsp)
distMatrix <- dist(scale(m))
fit <- hclust(distMatrix)
plot(fit)
rect.hclust(fit,k=10)
```


## Comment

- If you have any feedback or question, please post an issue [here](https://github.com/ropensci/textworkshop17/issues).
